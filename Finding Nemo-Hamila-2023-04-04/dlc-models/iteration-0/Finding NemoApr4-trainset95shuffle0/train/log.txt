2023-04-04 11:00:22 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['earr',
                      'earl',
                      'eyer',
                      'eyel',
                      'nose',
                      'throat',
                      'elbowr',
                      'elbowl',
                      'handr',
                      'handl',
                      'tailbase',
                      'tailtip',
                      'kneer',
                      'kneel',
                      'ankler',
                      'anklel'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Finding '
            'NemoApr4/Finding Nemo_Hamila95shuffle0.mat',
 'dataset_type': 'default',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': '/usr/local/lib/python3.9/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/efficientnet-b0/model.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Finding '
                'NemoApr4/Documentation_data-Finding Nemo_95shuffle0.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'efficientnet-b0',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': '/content/drive/MyDrive/DLC/Finding Nemo-Hamila-2023-04-04',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': '/content/drive/MyDrive/DLC/Finding '
                    'Nemo-Hamila-2023-04-04/dlc-models/iteration-0/Finding '
                    'NemoApr4-trainset95shuffle0/train/snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2023-04-04 11:03:09 iteration: 100 loss: 0.0488 lr: 0.0004999865777790546
2023-04-04 11:04:56 iteration: 200 loss: 0.0209 lr: 0.0004999462980777025
2023-04-04 11:06:08 iteration: 300 loss: 0.0189 lr: 0.0004998791264370084
2023-04-04 11:07:07 iteration: 400 loss: 0.0177 lr: 0.0004997851210646331
2023-04-04 11:07:56 iteration: 500 loss: 0.0173 lr: 0.0004996642819605768
2023-04-04 11:08:43 iteration: 600 loss: 0.0162 lr: 0.0004995165509171784
2023-04-04 11:09:31 iteration: 700 loss: 0.0151 lr: 0.0004993421025574207
2023-04-04 11:10:14 iteration: 800 loss: 0.0144 lr: 0.000499140762258321
2023-04-04 11:10:55 iteration: 900 loss: 0.0140 lr: 0.0004989127046428621
2023-04-04 11:11:32 iteration: 1000 loss: 0.0135 lr: 0.0004986578715033829
2023-04-04 11:12:08 iteration: 1100 loss: 0.0137 lr: 0.0004983763210475445
2023-04-04 11:12:42 iteration: 1200 loss: 0.0125 lr: 0.0004980681696906686
2023-04-04 11:13:18 iteration: 1300 loss: 0.0126 lr: 0.0004977332428097725
2023-04-04 11:13:46 iteration: 1400 loss: 0.0117 lr: 0.0004973717732354999
2023-04-04 11:14:20 iteration: 1500 loss: 0.0116 lr: 0.0004969836445525289
2023-04-04 11:14:50 iteration: 1600 loss: 0.0125 lr: 0.0004965690313838422
2023-04-04 11:15:19 iteration: 1700 loss: 0.0120 lr: 0.00049612793372944
2023-04-04 11:15:48 iteration: 1800 loss: 0.0116 lr: 0.000495660409796983
2023-04-04 11:16:17 iteration: 1900 loss: 0.0119 lr: 0.0004951664595864713
2023-04-04 11:16:47 iteration: 2000 loss: 0.0115 lr: 0.0004946461995132267
2023-04-04 11:17:16 iteration: 2100 loss: 0.0113 lr: 0.0004940996295772493
2023-04-04 11:17:46 iteration: 2200 loss: 0.0112 lr: 0.0004935268661938608
2023-04-04 11:18:13 iteration: 2300 loss: 0.0107 lr: 0.0004929279093630612
2023-04-04 11:18:42 iteration: 2400 loss: 0.0108 lr: 0.0004923028755001724
2023-04-04 11:19:11 iteration: 2500 loss: 0.0108 lr: 0.0004916518810205162
2023-04-04 11:19:40 iteration: 2600 loss: 0.0108 lr: 0.0004909748095087707
2023-04-04 11:20:08 iteration: 2700 loss: 0.0100 lr: 0.0004902720102109015
2023-04-04 11:20:38 iteration: 2800 loss: 0.0255 lr: 0.0004895433085039258
2023-04-04 11:21:04 iteration: 2900 loss: 0.0136 lr: 0.0004887888790108263
2023-04-04 11:21:32 iteration: 3000 loss: 0.0126 lr: 0.00048800883814692497
2023-04-04 11:22:00 iteration: 3100 loss: 0.0117 lr: 0.0004872033023275435
2023-04-04 11:22:29 iteration: 3200 loss: 0.0112 lr: 0.000486372213345021
2023-04-04 11:22:56 iteration: 3300 loss: 0.0107 lr: 0.0004855158331338316
2023-04-04 11:23:23 iteration: 3400 loss: 0.0103 lr: 0.0004846341034863144
2023-04-04 11:23:50 iteration: 3500 loss: 0.0108 lr: 0.00048372719902545214
2023-04-04 11:24:17 iteration: 3600 loss: 0.0094 lr: 0.00048279526527039707
2023-04-04 11:24:45 iteration: 3700 loss: 0.0097 lr: 0.00048183833132497966
2023-04-04 11:25:12 iteration: 3800 loss: 0.0093 lr: 0.0004808564845006913
2023-04-04 11:25:39 iteration: 3900 loss: 0.0086 lr: 0.0004798498994205147
2023-04-04 11:26:04 iteration: 4000 loss: 0.0089 lr: 0.00047881866339594126
2023-04-04 11:26:30 iteration: 4100 loss: 0.0083 lr: 0.0004777628928422928
2023-04-04 11:26:58 iteration: 4200 loss: 0.0085 lr: 0.0004766826459672302
2023-04-04 11:27:27 iteration: 4300 loss: 0.0084 lr: 0.00047557815560139716
2023-04-04 11:27:54 iteration: 4400 loss: 0.0081 lr: 0.00047444942174479365
2023-04-04 11:28:22 iteration: 4500 loss: 0.0081 lr: 0.00047329661902040243
2023-04-04 11:28:48 iteration: 4600 loss: 0.0077 lr: 0.0004721198929473758
2023-04-04 11:29:15 iteration: 4700 loss: 0.0076 lr: 0.00047091938904486597
2023-04-04 11:29:40 iteration: 4800 loss: 0.0079 lr: 0.0004696951655205339
2023-04-04 11:30:10 iteration: 4900 loss: 0.0083 lr: 0.00046844742610119283
2023-04-04 11:30:37 iteration: 5000 loss: 0.0073 lr: 0.0004671762580983341
2023-04-04 11:31:04 iteration: 5100 loss: 0.0075 lr: 0.0004658818361349404
2023-04-04 11:31:32 iteration: 5200 loss: 0.0069 lr: 0.0004645642766263336
2023-04-04 11:31:59 iteration: 5300 loss: 0.0074 lr: 0.000463223725091666
2023-04-04 11:32:27 iteration: 5400 loss: 0.0079 lr: 0.0004618603561539203
2023-04-04 11:32:54 iteration: 5500 loss: 0.0073 lr: 0.0004604743153322488
2023-04-04 11:33:22 iteration: 5600 loss: 0.0074 lr: 0.00045906571904197335
2023-04-04 11:33:48 iteration: 5700 loss: 0.0070 lr: 0.0004576347710099071
2023-04-04 11:34:16 iteration: 5800 loss: 0.0070 lr: 0.00045618158765137196
2023-04-04 11:34:42 iteration: 5900 loss: 0.0065 lr: 0.0004547063435893506
2023-04-04 11:35:08 iteration: 6000 loss: 0.0069 lr: 0.0004532091843429953
2023-04-04 11:35:36 iteration: 6100 loss: 0.0068 lr: 0.00045169031363911927
2023-04-04 11:36:03 iteration: 6200 loss: 0.0067 lr: 0.0004501498769968748
2023-04-04 11:36:29 iteration: 6300 loss: 0.0066 lr: 0.0004485879617277533
2023-04-04 11:36:57 iteration: 6400 loss: 0.0072 lr: 0.0004470049461815506
2023-04-04 11:37:24 iteration: 6500 loss: 0.0065 lr: 0.0004454008012544364
2023-04-04 11:37:51 iteration: 6600 loss: 0.0069 lr: 0.0004437757597770542
2023-04-04 11:38:17 iteration: 6700 loss: 0.0062 lr: 0.0004421300545800477
2023-04-04 11:38:45 iteration: 6800 loss: 0.0061 lr: 0.00044046377297490835
2023-04-04 11:39:11 iteration: 6900 loss: 0.0074 lr: 0.0004387772351037711
2023-04-04 11:39:37 iteration: 7000 loss: 0.0069 lr: 0.0004370704700704664
2023-04-04 11:40:04 iteration: 7100 loss: 0.0069 lr: 0.00043534382712095976
2023-04-04 11:40:32 iteration: 7200 loss: 0.0069 lr: 0.00043359730625525117
2023-04-04 11:40:58 iteration: 7300 loss: 0.0065 lr: 0.00043183128582313657
2023-04-04 11:41:25 iteration: 7400 loss: 0.0069 lr: 0.00043004582403227687
2023-04-04 11:41:53 iteration: 7500 loss: 0.0064 lr: 0.0004282411828171462
2023-04-04 11:42:19 iteration: 7600 loss: 0.0068 lr: 0.00042641753680072725
2023-04-04 11:42:46 iteration: 7700 loss: 0.0058 lr: 0.0004245751188136637
2023-04-04 11:43:13 iteration: 7800 loss: 0.0065 lr: 0.00042271404527127743
2023-04-04 11:43:41 iteration: 7900 loss: 0.0065 lr: 0.00042083460721187294
2023-04-04 11:44:08 iteration: 8000 loss: 0.0061 lr: 0.00041893700836226344
2023-04-04 11:44:34 iteration: 8100 loss: 0.0061 lr: 0.0004170214233454317
2023-04-04 11:45:00 iteration: 8200 loss: 0.0062 lr: 0.0004150880849920213
2023-04-04 11:45:26 iteration: 8300 loss: 0.0061 lr: 0.0004131371679250151
2023-04-04 11:45:54 iteration: 8400 loss: 0.0059 lr: 0.00041116890497505665
2023-04-04 11:46:21 iteration: 8500 loss: 0.0062 lr: 0.00040918352897278965
2023-04-04 11:46:49 iteration: 8600 loss: 0.0064 lr: 0.0004071812145411968
2023-04-04 11:47:16 iteration: 8700 loss: 0.0057 lr: 0.0004051622236147523
2023-04-04 11:47:43 iteration: 8800 loss: 0.0062 lr: 0.00040312675992026925
2023-04-04 11:48:09 iteration: 8900 loss: 0.0059 lr: 0.0004010750853922218
2023-04-04 11:48:37 iteration: 9000 loss: 0.0062 lr: 0.00039900740375742316
2023-04-04 11:49:03 iteration: 9100 loss: 0.0058 lr: 0.00039692388963885605
2023-04-04 11:49:30 iteration: 9200 loss: 0.0063 lr: 0.00039482483407482505
2023-04-04 11:49:57 iteration: 9300 loss: 0.0054 lr: 0.00039271044079214334
2023-04-04 11:50:21 iteration: 9400 loss: 0.0058 lr: 0.00039058091351762414
2023-04-04 11:50:49 iteration: 9500 loss: 0.0058 lr: 0.00038843657239340246
2023-04-04 11:51:14 iteration: 9600 loss: 0.0059 lr: 0.0003862775338348001
2023-04-04 11:51:39 iteration: 9700 loss: 0.0057 lr: 0.00038410420529544353
2023-04-04 11:52:06 iteration: 9800 loss: 0.0058 lr: 0.00038191667408682406
2023-04-04 11:52:32 iteration: 9900 loss: 0.0056 lr: 0.0003797151439357549
2023-04-04 11:52:58 iteration: 10000 loss: 0.0058 lr: 0.00037750002229586244
2023-04-04 11:53:24 iteration: 10100 loss: 0.0058 lr: 0.0003752714255824685
2023-04-04 11:53:52 iteration: 10200 loss: 0.0059 lr: 0.0003730296448338777
2023-04-04 11:54:16 iteration: 10300 loss: 0.0055 lr: 0.00037077494198456407
2023-04-04 11:54:44 iteration: 10400 loss: 0.0058 lr: 0.0003685075498651713
2023-04-04 11:55:10 iteration: 10500 loss: 0.0054 lr: 0.0003662276722025126
2023-04-04 11:55:35 iteration: 10600 loss: 0.0050 lr: 0.000363935629138723
2023-04-04 11:56:02 iteration: 10700 loss: 0.0058 lr: 0.0003616316244006157
2023-04-04 11:56:31 iteration: 10800 loss: 0.0058 lr: 0.0003593159490264952
2023-04-04 11:57:00 iteration: 10900 loss: 0.0061 lr: 0.0003569888067431748
2023-04-04 11:57:27 iteration: 11000 loss: 0.0058 lr: 0.000354650488588959
2023-04-04 11:57:57 iteration: 11100 loss: 0.0054 lr: 0.0003523012564983219
2023-04-04 11:58:26 iteration: 11200 loss: 0.0049 lr: 0.0003499413433019072
2023-04-04 11:58:55 iteration: 11300 loss: 0.0054 lr: 0.00034757101093418896
2023-04-04 11:59:21 iteration: 11400 loss: 0.0053 lr: 0.00034519052132964134
2023-04-04 11:59:50 iteration: 11500 loss: 0.0054 lr: 0.0003428001655265689
2023-04-04 12:00:18 iteration: 11600 loss: 0.0053 lr: 0.0003404001472517848
2023-04-04 12:00:47 iteration: 11700 loss: 0.0059 lr: 0.00033799081575125456
2023-04-04 12:01:17 iteration: 11800 loss: 0.0055 lr: 0.0003355723456479609
2023-04-04 12:01:47 iteration: 11900 loss: 0.0054 lr: 0.0003331450279802084
2023-04-04 12:02:14 iteration: 12000 loss: 0.0053 lr: 0.00033070918289013207
2023-04-04 12:02:45 iteration: 12100 loss: 0.0057 lr: 0.00032826498500071466
2023-04-04 12:03:15 iteration: 12200 loss: 0.0053 lr: 0.0003258128126617521
2023-04-04 12:03:46 iteration: 12300 loss: 0.0056 lr: 0.00032335284049622715
2023-04-04 12:04:16 iteration: 12400 loss: 0.0054 lr: 0.0003208853886462748
2023-04-04 12:04:46 iteration: 12500 loss: 0.0050 lr: 0.0003184106608387083
2023-04-04 12:05:14 iteration: 12600 loss: 0.0053 lr: 0.0003159290354233235
2023-04-04 12:05:42 iteration: 12700 loss: 0.0051 lr: 0.0003134407161269337
2023-04-04 12:06:11 iteration: 12800 loss: 0.0051 lr: 0.00031094596488401294
2023-04-04 12:06:40 iteration: 12900 loss: 0.0055 lr: 0.00030844510183669627
2023-04-04 12:07:11 iteration: 13000 loss: 0.0048 lr: 0.00030593835981562734
2023-04-04 12:07:39 iteration: 13100 loss: 0.0052 lr: 0.00030342605896294117
2023-04-04 12:08:07 iteration: 13200 loss: 0.0051 lr: 0.0003009084321092814
2023-04-04 12:08:35 iteration: 13300 loss: 0.0048 lr: 0.0002983857411891222
2023-04-04 12:09:06 iteration: 13400 loss: 0.0052 lr: 0.00029585836455225945
2023-04-04 12:09:38 iteration: 13500 loss: 0.0053 lr: 0.00029332644771784544
2023-04-04 12:10:08 iteration: 13600 loss: 0.0052 lr: 0.00029079033993184566
2023-04-04 12:10:37 iteration: 13700 loss: 0.0055 lr: 0.00028825030312873423
2023-04-04 12:11:07 iteration: 13800 loss: 0.0053 lr: 0.00028570665745064616
2023-04-04 12:11:39 iteration: 13900 loss: 0.0050 lr: 0.00028315960662439466
2023-04-04 12:12:10 iteration: 14000 loss: 0.0050 lr: 0.00028060947079211473
2023-04-04 12:12:41 iteration: 14100 loss: 0.0050 lr: 0.00027805654099211097
2023-04-04 12:13:11 iteration: 14200 loss: 0.0053 lr: 0.000275501050055027
2023-04-04 12:13:41 iteration: 14300 loss: 0.0049 lr: 0.00027294334722682834
2023-04-04 12:14:11 iteration: 14400 loss: 0.0050 lr: 0.00027038369444198906
2023-04-04 12:14:39 iteration: 14500 loss: 0.0046 lr: 0.0002678222954273224
2023-04-04 12:15:09 iteration: 14600 loss: 0.0046 lr: 0.00026525952853262424
2023-04-04 12:15:40 iteration: 14700 loss: 0.0051 lr: 0.0002626956265885383
2023-04-04 12:16:11 iteration: 14800 loss: 0.0050 lr: 0.0002601308806333691
2023-04-04 12:16:42 iteration: 14900 loss: 0.0047 lr: 0.0002575655817054212
2023-04-04 12:17:12 iteration: 15000 loss: 0.0050 lr: 0.0002550000208429992
2023-04-04 12:17:41 iteration: 15100 loss: 0.0045 lr: 0.0002524344017729163
2023-04-04 12:18:11 iteration: 15200 loss: 0.0050 lr: 0.00024986910284496844
2023-04-04 12:18:42 iteration: 15300 loss: 0.0044 lr: 0.0002473043859936297
2023-04-04 12:19:13 iteration: 15400 loss: 0.0050 lr: 0.00024474048404954374
2023-04-04 12:19:43 iteration: 15500 loss: 0.0048 lr: 0.00024217768805101514
2023-04-04 12:20:14 iteration: 15600 loss: 0.0042 lr: 0.00023961633269209415
2023-04-04 12:20:45 iteration: 15700 loss: 0.0049 lr: 0.00023705665080342442
2023-04-04 12:21:16 iteration: 15800 loss: 0.0048 lr: 0.00023449896252714097
2023-04-04 12:21:43 iteration: 15900 loss: 0.0045 lr: 0.00023194347159005702
2023-04-04 12:22:10 iteration: 16000 loss: 0.0048 lr: 0.00022939054179005325
2023-04-04 12:22:37 iteration: 16100 loss: 0.0046 lr: 0.00022684040595777333
2023-04-04 12:23:03 iteration: 16200 loss: 0.0048 lr: 0.00022429335513152182
2023-04-04 12:23:31 iteration: 16300 loss: 0.0044 lr: 0.00022174970945343375
2023-04-04 12:23:59 iteration: 16400 loss: 0.0047 lr: 0.00021920967265032232
2023-04-04 12:24:24 iteration: 16500 loss: 0.0046 lr: 0.00021667356486432254
2023-04-04 12:24:50 iteration: 16600 loss: 0.0043 lr: 0.00021414166258182377
2023-04-04 12:25:18 iteration: 16700 loss: 0.0049 lr: 0.00021161424228921533
2023-04-04 12:25:46 iteration: 16800 loss: 0.0038 lr: 0.0002090915950248018
2023-04-04 12:26:11 iteration: 16900 loss: 0.0035 lr: 0.0002065739536192268
2023-04-04 12:26:38 iteration: 17000 loss: 0.0026 lr: 0.00020406165276654065
2023-04-04 12:27:06 iteration: 17100 loss: 0.0023 lr: 0.00020155493984930217
2023-04-04 12:27:33 iteration: 17200 loss: 0.0020 lr: 0.00019905403314623982
2023-04-04 12:27:58 iteration: 17300 loss: 0.0019 lr: 0.00019655931100714952
2023-04-04 12:28:27 iteration: 17400 loss: 0.0020 lr: 0.0001940709917107597
2023-04-04 12:28:54 iteration: 17500 loss: 0.0018 lr: 0.00019158933719154447
2023-04-04 12:29:21 iteration: 17600 loss: 0.0018 lr: 0.0001891146384878084
2023-04-04 12:29:48 iteration: 17700 loss: 0.0017 lr: 0.0001866472011897713
2023-04-04 12:30:13 iteration: 17800 loss: 0.0019 lr: 0.00018418724357616156
2023-04-04 12:30:37 iteration: 17900 loss: 0.0016 lr: 0.00018173499847762287
2023-04-04 12:31:03 iteration: 18000 loss: 0.0017 lr: 0.00017929084424395114
2023-04-04 12:31:28 iteration: 18100 loss: 0.0016 lr: 0.00017685497005004436
2023-04-04 12:31:54 iteration: 18200 loss: 0.0016 lr: 0.00017442766693420708
2023-04-04 12:32:21 iteration: 18300 loss: 0.0017 lr: 0.00017200921138282865
2023-04-04 12:32:49 iteration: 18400 loss: 0.0017 lr: 0.00016959985077846795
2023-04-04 12:33:13 iteration: 18500 loss: 0.0014 lr: 0.0001671998470555991
2023-04-04 12:33:41 iteration: 18600 loss: 0.0014 lr: 0.00016480949125252664
2023-04-04 12:34:08 iteration: 18700 loss: 0.0014 lr: 0.00016242901619989425
2023-04-04 12:34:34 iteration: 18800 loss: 0.0015 lr: 0.00016005871293600649
2023-04-04 12:35:02 iteration: 18900 loss: 0.0014 lr: 0.00015769877063576132
2023-04-04 12:35:30 iteration: 19000 loss: 0.0013 lr: 0.000155349523993209
2023-04-04 12:35:57 iteration: 19100 loss: 0.0014 lr: 0.00015301122039090842
2023-04-04 12:36:23 iteration: 19200 loss: 0.0014 lr: 0.000150684078107588
2023-04-04 12:36:50 iteration: 19300 loss: 0.0014 lr: 0.00014836841728538275
2023-04-04 12:37:16 iteration: 19400 loss: 0.0013 lr: 0.00014606441254727542
2023-04-04 12:37:43 iteration: 19500 loss: 0.0014 lr: 0.00014377232582774013
2023-04-04 12:38:09 iteration: 19600 loss: 0.0014 lr: 0.00014149249182082713
2023-04-04 12:38:36 iteration: 19700 loss: 0.0012 lr: 0.00013922508514951915
2023-04-04 12:39:03 iteration: 19800 loss: 0.0012 lr: 0.00013697033864445984
2023-04-04 12:39:29 iteration: 19900 loss: 0.0013 lr: 0.0001347286015516147
2023-04-04 12:39:56 iteration: 20000 loss: 0.0012 lr: 0.00013250000483822078
2023-04-04 12:40:22 iteration: 20100 loss: 0.0015 lr: 0.00013028483954258263
2023-04-04 12:40:49 iteration: 20200 loss: 0.0014 lr: 0.00012808339670300484
2023-04-04 12:41:15 iteration: 20300 loss: 0.0013 lr: 0.0001258958363905549
2023-04-04 12:41:41 iteration: 20400 loss: 0.0013 lr: 0.00012372240598779172
2023-04-04 12:42:08 iteration: 20500 loss: 0.0013 lr: 0.00012156344018876553
2023-04-04 12:42:35 iteration: 20600 loss: 0.0012 lr: 0.00011941904813284054
2023-04-04 12:43:01 iteration: 20700 loss: 0.0012 lr: 0.00011728954268619418
2023-04-04 12:43:27 iteration: 20800 loss: 0.0011 lr: 0.00011517517850734293
2023-04-04 12:43:53 iteration: 20900 loss: 0.0011 lr: 0.00011307609383948147
2023-04-04 12:44:22 iteration: 21000 loss: 0.0013 lr: 0.00011099257972091436
2023-04-04 12:44:48 iteration: 21100 loss: 0.0011 lr: 0.00010892489808611572
2023-04-04 12:45:16 iteration: 21200 loss: 0.0013 lr: 0.0001068731871782802
2023-04-04 12:45:44 iteration: 21300 loss: 0.0011 lr: 0.00010483778169145808
2023-04-04 12:46:10 iteration: 21400 loss: 0.0010 lr: 0.00010281879076501355
2023-04-04 12:46:36 iteration: 21500 loss: 0.0011 lr: 0.00010081647633342072
2023-04-04 12:47:03 iteration: 21600 loss: 0.0013 lr: 9.883112943498418e-05
2023-04-04 12:47:31 iteration: 21700 loss: 0.0011 lr: 9.686285920906812e-05
2023-04-04 12:47:59 iteration: 21800 loss: 0.0012 lr: 9.491192031418905e-05
2023-04-04 12:48:25 iteration: 21900 loss: 0.0010 lr: 9.297859651269391e-05
2023-04-04 12:48:53 iteration: 22000 loss: 0.0010 lr: 9.106298966798931e-05
2023-04-04 12:49:21 iteration: 22100 loss: 0.0009 lr: 8.916534716263413e-05
2023-04-04 12:49:46 iteration: 22200 loss: 0.0010 lr: 8.728595275897533e-05
2023-04-04 12:50:13 iteration: 22300 loss: 0.0010 lr: 8.542490104446188e-05
2023-04-04 12:50:41 iteration: 22400 loss: 0.0011 lr: 8.358245395356789e-05
2023-04-04 12:51:07 iteration: 22500 loss: 0.0011 lr: 8.175884431693703e-05
2023-04-04 12:51:33 iteration: 22600 loss: 0.0011 lr: 7.995417399797589e-05
2023-04-04 12:52:02 iteration: 22700 loss: 0.0011 lr: 7.816872675903141e-05
2023-04-04 12:52:31 iteration: 22800 loss: 0.0012 lr: 7.640269177500159e-05
2023-04-04 12:52:57 iteration: 22900 loss: 0.0010 lr: 7.465620001312345e-05
2023-04-04 12:53:22 iteration: 23000 loss: 0.0009 lr: 7.292948430404067e-05
2023-04-04 12:53:49 iteration: 23100 loss: 0.0009 lr: 7.12227847543545e-05
2023-04-04 12:54:15 iteration: 23200 loss: 0.0011 lr: 6.953619595151395e-05
2023-04-04 12:54:42 iteration: 23300 loss: 0.0009 lr: 6.78699798299931e-05
2023-04-04 12:55:10 iteration: 23400 loss: 0.0011 lr: 6.622424552915618e-05
2023-04-04 12:55:38 iteration: 23500 loss: 0.0009 lr: 6.459922587964684e-05
2023-04-04 12:56:03 iteration: 23600 loss: 0.0010 lr: 6.299511733232066e-05
2023-04-04 12:56:29 iteration: 23700 loss: 0.0009 lr: 6.141201447462663e-05
2023-04-04 12:56:57 iteration: 23800 loss: 0.0010 lr: 5.98501501372084e-05
2023-04-04 12:57:23 iteration: 23900 loss: 0.0010 lr: 5.830972077092156e-05
2023-04-04 12:57:51 iteration: 24000 loss: 0.0009 lr: 5.679082460119389e-05
2023-04-04 12:58:19 iteration: 24100 loss: 0.0008 lr: 5.5293665354838595e-05
2023-04-04 12:58:47 iteration: 24200 loss: 0.0009 lr: 5.381844312069006e-05
2023-04-04 12:59:13 iteration: 24300 loss: 0.0008 lr: 5.236525248619728e-05
2023-04-04 12:59:41 iteration: 24400 loss: 0.0008 lr: 5.09342789882794e-05
2023-04-04 13:00:09 iteration: 24500 loss: 0.0009 lr: 4.952571907779202e-05
2023-04-04 13:00:39 iteration: 24600 loss: 0.0009 lr: 4.8139649152290076e-05
2023-04-04 13:01:05 iteration: 24700 loss: 0.0009 lr: 4.677626566262916e-05
2023-04-04 13:01:32 iteration: 24800 loss: 0.0009 lr: 4.543575778370723e-05
2023-04-04 13:01:59 iteration: 24900 loss: 0.0009 lr: 4.4118190999142826e-05
2023-04-04 13:02:26 iteration: 25000 loss: 0.0009 lr: 4.282375448383391e-05
2023-04-04 13:02:53 iteration: 25100 loss: 0.0009 lr: 4.1552604670869187e-05
2023-04-04 13:03:20 iteration: 25200 loss: 0.0008 lr: 4.030483978567645e-05
2023-04-04 13:03:47 iteration: 25300 loss: 0.0008 lr: 3.9080663555068895e-05
2023-04-04 13:04:14 iteration: 25400 loss: 0.0008 lr: 3.7880123272771016e-05
2023-04-04 13:04:41 iteration: 25500 loss: 0.0009 lr: 3.670338628580794e-05
2023-04-04 13:05:09 iteration: 25600 loss: 0.0009 lr: 3.5550619941204786e-05
2023-04-04 13:05:35 iteration: 25700 loss: 0.0008 lr: 3.4421896998537704e-05
2023-04-04 13:06:01 iteration: 25800 loss: 0.0008 lr: 3.331735933898017e-05
2023-04-04 13:06:28 iteration: 25900 loss: 0.0009 lr: 3.223715248168446e-05
2023-04-04 13:06:55 iteration: 26000 loss: 0.0008 lr: 3.118135646218434e-05
2023-04-04 13:07:23 iteration: 26100 loss: 0.0008 lr: 3.0150098609738052e-05
2023-04-04 13:07:50 iteration: 26200 loss: 0.0008 lr: 2.9143531719455495e-05
2023-04-04 13:08:19 iteration: 26300 loss: 0.0008 lr: 2.816170672303997e-05
2023-04-04 13:08:46 iteration: 26400 loss: 0.0007 lr: 2.7204747311770916e-05
2023-04-04 13:09:13 iteration: 26500 loss: 0.0009 lr: 2.62727899098536e-05
2023-04-04 13:09:40 iteration: 26600 loss: 0.0008 lr: 2.536590545787476e-05
2023-04-04 13:10:08 iteration: 26700 loss: 0.0007 lr: 2.4484195819240995e-05
2023-04-04 13:10:34 iteration: 26800 loss: 0.0008 lr: 2.3627781047252938e-05
2023-04-04 13:11:00 iteration: 26900 loss: 0.0008 lr: 2.2796730263507925e-05
2023-04-04 13:11:27 iteration: 27000 loss: 0.0007 lr: 2.1991134417476133e-05
2023-04-04 13:11:53 iteration: 27100 loss: 0.0008 lr: 2.1211122657405213e-05
2023-04-04 13:12:20 iteration: 27200 loss: 0.0008 lr: 2.0456709535210393e-05
2023-04-04 13:12:48 iteration: 27300 loss: 0.0008 lr: 1.972805694094859e-05
2023-04-04 13:13:17 iteration: 27400 loss: 0.0008 lr: 1.90251630556304e-05
2023-04-04 13:13:43 iteration: 27500 loss: 0.0008 lr: 1.8348162484471686e-05
2023-04-04 13:14:07 iteration: 27600 loss: 0.0007 lr: 1.769712434906978e-05
2023-04-04 13:14:35 iteration: 27700 loss: 0.0008 lr: 1.707209594314918e-05
2023-04-04 13:15:03 iteration: 27800 loss: 0.0007 lr: 1.647316457820125e-05
2023-04-04 13:15:29 iteration: 27900 loss: 0.0007 lr: 1.5900397556833923e-05
2023-04-04 13:15:55 iteration: 28000 loss: 0.0007 lr: 1.5353833077824675e-05
2023-04-04 13:16:22 iteration: 28100 loss: 0.0007 lr: 1.483355117670726e-05
2023-04-04 13:16:50 iteration: 28200 loss: 0.0007 lr: 1.4339630070026033e-05
2023-04-04 13:17:16 iteration: 28300 loss: 0.0008 lr: 1.3872066119802184e-05
2023-04-04 13:17:42 iteration: 28400 loss: 0.0007 lr: 1.343096391792642e-05
2023-04-04 13:18:08 iteration: 28500 loss: 0.0007 lr: 1.3016350749239791e-05
2023-04-04 13:18:35 iteration: 28600 loss: 0.0007 lr: 1.262827299797209e-05
2023-04-04 13:19:01 iteration: 28700 loss: 0.0007 lr: 1.2266772500879597e-05
2023-04-04 13:19:25 iteration: 28800 loss: 0.0008 lr: 1.1931892913707998e-05
2023-04-04 13:19:51 iteration: 28900 loss: 0.0007 lr: 1.162366424978245e-05
2023-04-04 13:20:18 iteration: 29000 loss: 0.0007 lr: 1.1342131074343342e-05
2023-04-04 13:20:42 iteration: 29100 loss: 0.0007 lr: 1.1087321581726428e-05
2023-04-04 13:21:10 iteration: 29200 loss: 0.0008 lr: 1.0859248504857533e-05
2023-04-04 13:21:35 iteration: 29300 loss: 0.0007 lr: 1.0657959137461148e-05
2023-04-04 13:22:01 iteration: 29400 loss: 0.0008 lr: 1.0483451660547871e-05
2023-04-04 13:22:27 iteration: 29500 loss: 0.0007 lr: 1.033575608744286e-05
2023-04-04 13:22:54 iteration: 29600 loss: 0.0008 lr: 1.0214899702987168e-05
2023-04-04 13:23:19 iteration: 29700 loss: 0.0007 lr: 1.0120899787580129e-05
2023-04-04 13:23:48 iteration: 29800 loss: 0.0007 lr: 1.0053725418401882e-05
2023-04-04 13:24:13 iteration: 29900 loss: 0.0006 lr: 1.0013435712608043e-05
2023-04-04 13:24:38 iteration: 30000 loss: 0.0008 lr: 1.0000000656873453e-05
